{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5aa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from random import *\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3c026",
   "metadata": {},
   "source": [
    "# 1- Dataset\n",
    "Cet ensemble de données se compose de 3 types différents de longueurs de pétales et de sépales d'iris (Setosa, Versicolor et Virginica), stockés dans un numpy.ndarray de 150x4\n",
    "\n",
    "Les rangées étant les échantillons et les colonnes étant : la longueur des sépales, la largeur des sépales, la longueur des pétales et la largeur des pétales.\n",
    "\n",
    "Le graphique ci-dessous utilise les deux premières fonctionnalités. Voir ici pour plus d'informations sur cet ensemble de données.\n",
    "![title](img\\iris.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b0e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len X = (150, 4)\n",
      "len Y (150,)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, Y = shuffle(iris.data, iris.target)\n",
    "print(\"len X =\",np.shape(X))\n",
    "print(\"len Y\",np.shape(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bee60",
   "metadata": {},
   "source": [
    "# Fonction de distance :Distance écludien\n",
    "Soit ($X_1$,...,$X_n$) notre donné d'apprentissage avec $\\forall$$i$ $\\in$ $[$$1..n$$]$ $dim$($X_i$)=$n$ \n",
    "on définit la distance écludien de $X_i$ et $X_j$ par $d$$($$X_i$$,$$X_j$$)$= $\\sum (X_{ik}-X_{jk})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcbba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclud_dist(X_i,X_j):\n",
    "    dim=np.shape(X_i)[0]\n",
    "    assert(dim == np.shape(X_j)[0])\n",
    "    dist=0\n",
    "    for k in range(dim):\n",
    "        dist+=(X_i[k]-X_j[k])**2\n",
    "    return dist        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b704f41",
   "metadata": {},
   "source": [
    "# Deviser les donnés en train(70%) et test(30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cc4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len (105, 4)\n",
      "Y_train len (105,)\n",
      "X_test len (45, 4)\n",
      "Y_test len (45,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.30)\n",
    "print(\"X_train len\",np.shape(X_train))\n",
    "print(\"Y_train len\",np.shape(y_train))\n",
    "print(\"X_test len\",np.shape(X_test))\n",
    "print(\"Y_test len\",np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78709e0e",
   "metadata": {},
   "source": [
    "# Algorithme K plus proches voisins\n",
    "![title](img/KNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a46e1",
   "metadata": {},
   "source": [
    "$\\textbf{Entré Vecteur X et l'ensemble d'apprentissage D et le paremetre K}$$\\newline$ \n",
    "$\\textbf{Sortir : la classe de X}$ $\\newline$ \n",
    "$\\textbf{1)Calculer la distance de X à tous les instances de D}$ $\\newline$ \n",
    "$\\textbf{2)Prenez les K voisins les plus proches à X en fonction de la distance euclidienne calculée.}$ $\\newline$ \n",
    "$\\textbf{3)Dans les k voisins, comptez le nombre de points de données dans chaque classe.}$ $\\newline$\n",
    "$\\textbf{4)Attribuez X à la classe avec le plus grand nombre de voisins}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4322c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbour(X,Data_set,labels,k=1):\n",
    "    nb_instance=max(np.shape(Data_set)[0],np.shape(Data_set)[1])# nombre d'instrance\n",
    "    nb_labels=np.shape(labels)[0]#nombre de classe\n",
    "    assert(nb_instance==nb_labels)#assert nombre de classe == nombre d'instance\n",
    "    assert(k<=nb_instance) #assert k <= nombre d'instance avant implementer l'algo\n",
    "    dim=min(np.shape(Data_set)[0],np.shape(Data_set)[1])#dimention de X : nombre de features\n",
    "    \n",
    "    #calcule de distance de X a tous les instances\n",
    "    distance_all_instance=[]\n",
    "    for i in range(nb_instance):\n",
    "        dist_ecld=eclud_dist(X,Data_set[i])\n",
    "        distance_all_instance.append({\"dist\":dist_ecld,\"classe\":labels[i]})\n",
    "    \n",
    "    #trier la liste de distance\n",
    "    distance_all_instance_sorted=sorted(distance_all_instance, key=lambda x: x['dist'])\n",
    "    \n",
    "    #chercher les k plus proche voisin de X\n",
    "    k_nearest_instance=[]\n",
    "    for i in range(k):\n",
    "        k_nearest_instance.append(distance_all_instance_sorted[i])\n",
    "    \n",
    "    #les classes de k plus proche voisin de X\n",
    "    classes={\"0\":0,\"1\":1,\"2\":2}\n",
    "    for neighbour in k_nearest_instance:\n",
    "        classes[str(neighbour['classe'])]+=1\n",
    "    \n",
    "    classe=\"0\"\n",
    "    \n",
    "    for key in classes.keys():\n",
    "        if classes[key]>classes[classe]:\n",
    "            classe=key\n",
    "    return classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d2f46",
   "metadata": {},
   "source": [
    "# évaluation de KNN\n",
    "Soit $C$ notre classifieur avec$\\newline$ \n",
    "$\\begin{array}{ccccc}\n",
    "C & : & \\Omega ^n & \\to & \\{0,1,2\\} \\\\\n",
    " & & X & \\mapsto & C(X) \\\\\n",
    "\\end{array}$ $\\newline$\n",
    "et Soit $D=\\{(X_1,Y_1)..(X_p,Y_p)\\}$ notre donné de test pour évaluer le classifier $C$ on définit $\\newline$ \n",
    "$accuracy(C,D) = \\frac{1}{p} \\sum_{i=1}^{p} \\mathbb{1}(C(X_i),Y_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72d3e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_KNN(data_test):\n",
    "    accuracy=0\n",
    "    for instance,real_class in data_test:\n",
    "        if int(k_nearest_neighbour(instance,X_train,y_train,k=2))==real_class:\n",
    "            accuracy+=1\n",
    "    print(\"accuracy =\",accuracy//len(data_test))\n",
    "    return accuracy/len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f46532c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "for i in range(np.shape(X_test)[0]):\n",
    "    data_test.append((X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b930d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_KNN(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8f094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
